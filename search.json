[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mining Acknowledgements Sections",
    "section": "",
    "text": "While the current scholarly effort of literature review focuses on understanding published works’ vision, content, method, results, limitation, etc., we aim to find meaningful information from the acknowledgment sections of research papers. Although the acknowledgment section appears in most research papers, as far as we know, they do not gather much interest. We want to understand the different elements of the acknowledgment section, how they are organized, and within a specific field, are there frequently mentioned names and entities? In addition, we will discuss how to incorporate these findings to present helpful information to users when they search looking for related research interests."
  },
  {
    "objectID": "index.html#original-dataset",
    "href": "index.html#original-dataset",
    "title": "Mining Acknowledgements Sections",
    "section": "Original Dataset",
    "text": "Original Dataset\nThe original dataset of 64 papers was provided to us as a large JSON file that had a lot data within it. For our analysis of acknowledgements sections we only needed a few data points to get started. The original dataset is available below for exploration (minor change just to make it render nicely).\n\n\nShow Code for Loading the Original Dataset\nfrom IPython.display import JSON\nimport json\n\nwith open(\"data/599_lit_review.json\", \"r\") as open_f:\n    original_dataset = json.load(open_f)\n    \nJSON({\"data\": original_dataset})\n\n\n<IPython.core.display.JSON object>"
  },
  {
    "objectID": "index.html#compiled-dataset",
    "href": "index.html#compiled-dataset",
    "title": "Mining Acknowledgements Sections",
    "section": "Compiled Dataset",
    "text": "Compiled Dataset\nFor our analysis, we really only needed some metadata and a view or download link for each paper which we could then manually go and copy-paste any acknowledgements section into our dataset (we have some thoughts as to how to automate this in Section 7).\nTo extract the data we needed we ran the following code:\n\n\nShow Code for Compile Dataset for Manual Addition\nimport pandas as pd\n\ncompiled_rows = []\nfor index, paper in enumerate(original_dataset):\n    # Some papers have data from CSL and some from S2\n    # Get both so we don't really have to care later on\n    \n    # Check if the paper has CSL data at all\n    if paper.get(\"csl\", None) is not None:\n        # Find or get title and url returned by CSL data\n        csl_title = paper[\"csl\"].get(\"title\", None)\n        csl_url = paper[\"csl\"].get(\"URL\", None)\n    else:\n        csl_title = None\n        csl_url = None\n\n    # Check if the paper has Semantic Scholar data at all\n    if paper.get(\"s2data\", None) is not None:\n        # Find or get title and url returned by S2 data\n        s2_title = paper[\"s2data\"].get(\"title\", None)\n        s2_url = paper[\"s2data\"].get(\"url\", None)\n    else:\n        s2_title = None\n        s2_url = None\n    \n    # Compile all results\n    compiled_rows.append({\n        \"paper_index\": index,\n        \"doi\": paper[\"doi\"],\n        \"s2id\": paper.get(\"s2id\", None),\n        \"s2_url\": s2_url,\n        \"csl_url\": csl_url,\n        \"s2_title\": s2_title,\n        \"csl_title\": csl_title,\n        \"acknowledgements_text\": None,\n    })\n    \ncompiled_dataset = pd.DataFrame(compiled_rows)\n\n\nOur dataset after adding all the acknowledgements sections is available below:\n\n\nRead and Show Data with Acknowledgements Sections Added\nfrom itables import show\nimport itables.options as table_opts\ntable_opts.lengthMenu = [5, 10, 25, 50]\n\nraw_data = pd.read_csv(\"data/raw-ack-sections.csv\")\nshow(raw_data)\n\n\n\n\n    \n      \n      paper_index\n      doi\n      s2id\n      s2_url\n      csl_url\n      s2_title\n      csl_title\n      acknowledgements_text\n    \n  Loading... (need help?)"
  },
  {
    "objectID": "index.html#ner",
    "href": "index.html#ner",
    "title": "Mining Acknowledgements Sections",
    "section": "NER",
    "text": "NER\nWe can now take each of these acknowledgements sections and run them through a named entity recognition model.\n\nimport spacy\n# import spacy_transformers\n\nnlp = spacy.load(\"en_core_web_trf\")\n\n# Filter dataset to only include rows with acknowledgements sections\nfiltered_data = raw_data.dropna(subset=[\"acknowledgements_text\"])\n\n# For each acknowledgement, run it through spacy,\n# extract entities and their labels and store to a dataframe\nentities_rows = []\ndocs = []\nfor _, paper in filtered_data.iterrows():\n    doc = nlp(paper.acknowledgements_text)\n    docs.append(doc)\n    for ent in doc.ents:\n        # Store with the DOI so we can join with other data later\n        entities_rows.append({\n            \"doi\": paper.doi,\n            \"entity\": ent.text,\n            \"entity_label\": ent.label_,\n        })\n        \nentities = pd.DataFrame(entities_rows)\n\n\n# How did the model tag each of these examples?\nfrom spacy import displacy\n\ndisplacy.render(pd.Series(docs).sample(3).to_list(), style=\"ent\")\n\nThe author wishes to thank \n\n    Mary Barton\n    PERSON\n\n for a thoughtful reading and response to this work, \n\n    Anne White\n    PERSON\n\n for her assistance, and \n\n    the Fannie and Alan Leslie Center for the Humanities\n    ORG\n\n at \n\n    Dartmouth College\n    ORG\n\n, where this piece was researched and written.\n\n\n\n    Distill\n    ORG\n\n has been supported by too many people over \n\n    the years\n    DATE\n\n to have any hope of thanking everyone. We’re especially grateful to \n\n    Distill\n    ORG\n\n’s authors for investing so much in their articles, and to our reviewers for generously giving so much time to help \n\n    Distill\n    ORG\n\n. We’re also grateful to the many people who helped us as we struggled with this decision over \n\n    the last few years\n    DATE\n\n. Many people took time to talk with us about burn out, about whether \n\n    Distill\n    ORG\n\n was a good structure, about how to wind \n\n    Distill\n    ORG\n\n down graciously, and about this essay. We’re also grateful to past and present \n\n    Distill\n    ORG\n\n authors for being so understanding of our decision.\n\nWe thank \n\n    Regina Cheng\n    PERSON\n\n and \n\n    Nathan Hassanzadeh\n    PERSON\n\n for theirhelp collecting and analyzing data for Studies \n\n    2\n    CARDINAL\n\n and \n\n    3\n    CARDINAL\n\n.  This research   was   funded   by \n\n    NSF\n    ORG\n\n   grants \n\n    #1319829\n    MONEY\n\n and \n\n    #1735234\n    MONEY\n\n as well as \n\n    NLM\n    ORG\n\n grant #T15LM011271."
  },
  {
    "objectID": "index.html#quick-analysis",
    "href": "index.html#quick-analysis",
    "title": "Mining Acknowledgements Sections",
    "section": "Quick Analysis",
    "text": "Quick Analysis\nHere are the most common entity types:\n\nimport altair as alt\n\nalt.Chart(entities).mark_bar().encode(\n    alt.X(\"entity_label\", sort=\"-y\"),\n    y=\"count()\",\n    color=\"entity_label\",\n    tooltip=[\"entity_label\", \"count()\"],\n).properties(\n    width=400,\n    height=300\n).interactive()\n\n\n\n\n\n\n\nA bulk of the named entities are people and organizations (which is what we would expect and what we are looking for), we can filter out the rest.\n\n# Filter all rows that aren't people or orgs\npeople_and_org_refs = entities.loc[entities.entity_label.isin([\"PERSON\", \"ORG\"])]\n\nThis is still too much data to visualize each person or org’s count so let’s just visualize a the top ten referenced people or entities.\n\n# Top ten entities including people and organization\ntop_ten_entities = people_and_org_refs.value_counts(\n    subset=[\"entity\", \"entity_label\"]\n).to_frame().reset_index().rename(columns={0: \"count\"})[:10]\n\n# Render\nalt.Chart(top_ten_entities).mark_bar().encode(\n    alt.X(\"entity\", sort=\"-y\"),\n    y=\"count\",\n    color=\"entity_label\",\n    tooltip=[\"entity\", \"entity_label\", \"count\"],\n).properties(\n    width=400,\n    height=300\n).interactive()\n\n\n\n\n\n\nLet’s clean up some of the duplicates we see here and some of the duplicates we manually spotted throughout the dataset.\n\n# Combine duplicate entities\npeople_and_org_refs['entity'] = people_and_org_refs['entity'].replace(\n    ['the National Science Foundation', 'National Science Foundation'], 'NSF'\n)\npeople_and_org_refs['entity'] = people_and_org_refs['entity'].replace(\n    ['Ofce of Naval Research', 'the Office of Naval Research'], 'ONS'\n)\npeople_and_org_refs['entity'] = people_and_org_refs['entity'].replace(\n    ['the ArmyResearch  Laboratory', 'the  Army  Research  Labora-tory'], 'the  Army  Research  Laboratory'\n)\npeople_and_org_refs['entity'] = people_and_org_refs['entity'].replace(\n    ['AI2'], 'the Allen Institute for AI'\n)\npeople_and_org_refs['entity'] = people_and_org_refs['entity'].replace(\n    ['the University of\\nWashington', 'National Science Foundation'], 'The University of Washington'\n)\npeople_and_org_refs['entity'] = people_and_org_refs['entity'].replace(\n    ['the Alfred P. Sloan Foun- dation', 'the Alfred\\nP. Sloan Foundation'], 'the Alfred P. Sloan Foundation'\n)\n\n\n# Regenerate the top ten list selections\n\n# Top ten entities including people and organization\ntop_ten_entities = people_and_org_refs.value_counts(\n    subset=[\"entity\", \"entity_label\"]\n).to_frame().reset_index().rename(columns={0: \"count\"})[:10]\n\n# Render\nalt.Chart(top_ten_entities).mark_bar().encode(\n    alt.X(\"entity\", sort=\"-y\"),\n    y=\"count\",\n    color=\"entity_label\",\n    tooltip=[\"entity\", \"entity_label\", \"count\"],\n).properties(\n    width=400,\n    height=300\n).interactive()\n\n\n\n\n\n\nIf we are interested in organizations which may fund this type of research or that we should potentially partner with, we can just look at the top organizations.\n\n# Top ten orgs\ntop_ten_orgs = people_and_org_refs.loc[people_and_org_refs[\"entity_label\"] == \"ORG\"].value_counts(\n    subset=[\"entity\", \"entity_label\"]\n).to_frame().reset_index().rename(columns={0: \"count\"})[:10]\n\n# Render\nalt.Chart(top_ten_orgs).mark_bar().encode(\n    alt.X(\"entity\", sort=\"-y\"),\n    y=\"count\",\n    color=\"entity\",\n    tooltip=[\"entity\", \"entity_label\", \"count\"],\n).properties(\n    width=400,\n    height=300\n).interactive()\n\n\n\n\n\n\nWho are the people that help this type of research who may be underappreciated? Software devs, data archivists, or just people who are good to talk to?\n\n# Top ten people\ntop_ten_people = people_and_org_refs.loc[people_and_org_refs[\"entity_label\"] == \"PERSON\"].value_counts(\n    subset=[\"entity\", \"entity_label\"]\n).to_frame().reset_index().rename(columns={0: \"count\"})[:10]\n\n# Render\nalt.Chart(top_ten_people).mark_bar().encode(\n    alt.X(\"entity\", sort=\"-y\"),\n    y=\"count\",\n    color=\"entity\",\n    tooltip=[\"entity\", \"entity_label\", \"count\"],\n).properties(\n    width=400,\n    height=300\n).interactive()"
  },
  {
    "objectID": "index.html#incorporate-organization-information-in-semantic-scholar-search-engine",
    "href": "index.html#incorporate-organization-information-in-semantic-scholar-search-engine",
    "title": "Mining Acknowledgements Sections",
    "section": "Incorporate Organization Information in Semantic Scholar Search Engine",
    "text": "Incorporate Organization Information in Semantic Scholar Search Engine\nThe organization names we extracted from the acknowledgement section can provide funding information for researchers. It also tells users which organizations and institutes are interested in related research topics. Here is one potential method of how we might use this information in a different search process.\n\n\n\nSearch Page\n\n\n\n\n\nfunding"
  },
  {
    "objectID": "index.html#sec-automation",
    "href": "index.html#sec-automation",
    "title": "Mining Acknowledgements Sections",
    "section": "Ideas on Automation",
    "text": "Ideas on Automation\nA lot of this can be automated. We did the manual collection of the acknowledgements sections because it was a small set of 64 papers but this is entirely possible to automate with the recent advancements in PDF -> HTML renders. If the paper is presented in an HTML view then scrape directly, if you can use a PDF -> HTML system, then do that, and then scrape, if that doesn’t work, it might still be possible to just extract all the text from the PDF. A larger set of acknowledgements to mine would be really interesting to see if there are people who are commonly acknowledged but have less papers or citations. We briefly talked about how software citation is beginning to increase (esp. in the Computational Biology space) but historically, a lot of research software developers have been relegated to the acknowledgements section.\nFurther, we wanted to extend this idea and build a classifier to identify the type of acknowledge the organization or individual received. Was the acknowledgement “in thanks for discussion?” What the acknowledgment “in thanks for data?” Etc. We ultimately didn’t end up doing this because we ran out of time but it seems like it might be something fun and interesting to revisit."
  },
  {
    "objectID": "index.html#side-discoveries",
    "href": "index.html#side-discoveries",
    "title": "Mining Acknowledgements Sections",
    "section": "Side Discoveries",
    "text": "Side Discoveries\nWe did a content analysis of acknowledgement section and here is the results and our qualitative classification. Future research may can automaticlly tag different classification to the NER names.\n\n\n\nfunding"
  }
]
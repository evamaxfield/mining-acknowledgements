{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9b5ee167-4893-470b-b815-16a1661d559a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Mining Acknowledgements Sections\"\n",
    "author: \"Eva Maxfield Brown and Chris Fu\"\n",
    "date: \"October 28, 2022\"\n",
    "\n",
    "toc: true\n",
    "toc-location: left\n",
    "format:\n",
    "  html:\n",
    "    code-tools: true\n",
    "    standalone: true\n",
    "    embed-resources: true\n",
    "\n",
    "reference-location: margin\n",
    "citation-location: margin\n",
    "csl: support/nature.csl\n",
    "\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4cadf-1c9b-4181-968f-3e4450e2d54d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "While the current scholarly effort of literature review focuses on understanding published works' vision, content, method, results, limitation, etc., we aim to find meaningful information from research papers' acknowledgment section. The acknowledgment section appears in most research papers but does not gather much interest as we know. We want to understand the different aspects of the acknowledgment section, how they are organized, and within a specific field, are there frequently mentioned names and entities? In addition, we will discuss how to incorporate these findings to present helpful information to readers when they use search engines looking for related research interests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c70102-073f-46ff-92e5-7ffc168a2301",
   "metadata": {},
   "source": [
    "## Original Dataset\n",
    "\n",
    "The original dataset of 64 papers was provided to us as a large JSON file that had a lot data within it. For our analysis of acknowledgements sections we only needed a few data points to get started. The original dataset is available below for exploration (minor change just to make it render nicely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720e243-adb9-4612-a349-545c8c128aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show Code for Loading the Original Dataset\"\n",
    "\n",
    "from IPython.display import JSON\n",
    "import json\n",
    "\n",
    "with open(\"data/599_lit_review.json\", \"r\") as open_f:\n",
    "    original_dataset = json.load(open_f)\n",
    "    \n",
    "JSON({\"data\": original_dataset})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f42ca-ca2e-4571-8b79-34bfab11c8d7",
   "metadata": {},
   "source": [
    "## Compiled Dataset\n",
    "\n",
    "For our analysis, we really only needed some metadata and a view or download link for each paper which we could then manually go and copy-paste any acknowledgements section into our dataset (we have some thoughts as to how to automate this in a later section).\n",
    "\n",
    "To extract the data we needed we ran the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f8c02-c752-4737-84f4-57500f7f9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show Code for Compile Dataset for Manual Addition\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "compiled_rows = []\n",
    "for index, paper in enumerate(original_dataset):\n",
    "    # Some papers have data from CSL and some from S2\n",
    "    # Get both so we don't really have to care later on\n",
    "    \n",
    "    # Check if the paper has CSL data at all\n",
    "    if paper.get(\"csl\", None) is not None:\n",
    "        # Find or get title and url returned by CSL data\n",
    "        csl_title = paper[\"csl\"].get(\"title\", None)\n",
    "        csl_url = paper[\"csl\"].get(\"URL\", None)\n",
    "    else:\n",
    "        csl_title = None\n",
    "        csl_url = None\n",
    "\n",
    "    # Check if the paper has Semantic Scholar data at all\n",
    "    if paper.get(\"s2data\", None) is not None:\n",
    "        # Find or get title and url returned by S2 data\n",
    "        s2_title = paper[\"s2data\"].get(\"title\", None)\n",
    "        s2_url = paper[\"s2data\"].get(\"url\", None)\n",
    "    else:\n",
    "        s2_title = None\n",
    "        s2_url = None\n",
    "    \n",
    "    # Compile all results\n",
    "    compiled_rows.append({\n",
    "        \"paper_index\": index,\n",
    "        \"doi\": paper[\"doi\"],\n",
    "        \"s2id\": paper.get(\"s2id\", None),\n",
    "        \"s2_url\": s2_url,\n",
    "        \"csl_url\": csl_url,\n",
    "        \"s2_title\": s2_title,\n",
    "        \"csl_title\": csl_title,\n",
    "        \"acknowledgements_text\": None,\n",
    "    })\n",
    "    \n",
    "compiled_dataset = pd.DataFrame(compiled_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063222c4-7fb2-468b-8e3d-6d6a6446457f",
   "metadata": {},
   "source": [
    "Our dataset after adding all the acknowledgements sections is available below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf675bc-d56e-460e-9948-923a5ab26f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Read and Show Data with Acknowledgements Sections Added\"\n",
    "\n",
    "from itables import show\n",
    "import itables.options as table_opts\n",
    "table_opts.lengthMenu = [5, 10, 25, 50]\n",
    "\n",
    "raw_data = pd.read_csv(\"data/raw-ack-sections.csv\")\n",
    "show(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d124badc-76dc-42ff-8930-33eb3c2e4148",
   "metadata": {},
   "source": [
    "## NER\n",
    "\n",
    "We can now take each of these acknowledgements sections and run them through a named entity recognition model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de9e92-a3db-4e72-8c14-d29414ed39a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: \"Download the Spacy Model\"\n",
    "#| echo: false\n",
    "\n",
    "# Note there is a larger / more accuract model available with: \"en_core_web_trf\"\n",
    "# Run this outside of Jupyter\n",
    "# python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f0fd7-3a3c-4846-8620-cd56f5dee095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: \"Run NER Across the Whole Dataset\"\n",
    "#| warning: false\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Filter dataset to only include rows with acknowledgements sections\n",
    "filtered_data = raw_data.dropna(subset=[\"acknowledgements_text\"])\n",
    "\n",
    "# For each acknowledgement, run it through spacy,\n",
    "# extract entities and their labels and store to a dataframe\n",
    "entities_rows = []\n",
    "docs = []\n",
    "for _, paper in filtered_data.iterrows():\n",
    "    doc = nlp(paper.acknowledgements_text)\n",
    "    docs.append(doc)\n",
    "    for ent in doc.ents:\n",
    "        # Store with the DOI so we can join with other data later\n",
    "        entities_rows.append({\n",
    "            \"doi\": paper.doi,\n",
    "            \"entity\": ent.text,\n",
    "            \"entity_label\": ent.label_,\n",
    "        })\n",
    "        \n",
    "entities = pd.DataFrame(entities_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aaeb68-05b9-4a3a-996f-a326a57cbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How did the model tag each of these examples?\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display, HTML\n",
    "from spacy import displacy\n",
    "\n",
    "@interact\n",
    "def render_example(doc_index=list(range(len(docs)))):\n",
    "    return display(HTML(displacy.render(docs[doc_index], style=\"ent\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce4fb4",
   "metadata": {},
   "source": [
    "Here are the most common entity types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b8932-7dcb-4613-8d3b-c600884ab421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| warning: false\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "alt.Chart(entities).mark_bar().encode(\n",
    "    alt.X(\"entity_label\", sort=\"-y\"),\n",
    "    y=\"count()\",\n",
    "    color=\"entity_label\",\n",
    "    tooltip=[\"entity_label\", \"count()\"],\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50705fee",
   "metadata": {},
   "source": [
    "A bulk of the named entities are people and organizations (which is what we would expect and what we are looking for), we can filter out the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a626d1-0ebc-4c37-b09b-2e4b316f543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all rows that aren't people or orgs\n",
    "people_and_org_refs = entities.loc[entities.entity_label.isin([\"PERSON\", \"ORG\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d030ed",
   "metadata": {},
   "source": [
    "This is still too much data to visualize each person or org's count so let's just visualize a the top ten referenced people or entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff96b9-9c9c-4601-81de-b607d5ee3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten_entities = people_and_org_refs.value_counts(\n",
    "    subset=[\"entity\", \"entity_label\"]\n",
    ").to_frame().reset_index().rename(columns={0: \"count\"})[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f293e23-09af-4e5a-9fb3-002194cc0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| warning: false\n",
    "\n",
    "alt.Chart(top_ten_entities).mark_bar().encode(\n",
    "    alt.X(\"entity\", sort=\"-y\"),\n",
    "    y=\"count\",\n",
    "    color=\"entity\",\n",
    "    tooltip=[\"entity\", \"entity_label\", \"count\"],\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84876cf5-b06b-46df-b24d-37e75796a8b9",
   "metadata": {},
   "source": [
    "## Classifying Recognition\n",
    "\n",
    "blah"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
